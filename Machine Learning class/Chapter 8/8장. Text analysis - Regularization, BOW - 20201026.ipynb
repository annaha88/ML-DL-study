{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 전처리(텍스트 정규화)\n",
    "- NLTK(Natural Language Toolkit for Python) : 자연어 처리 패키지\n",
    "- 설치 및 실습 : pip install nltk\n",
    "\n",
    "- documentation :https://www.nltk.org/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "# send_tokenize : 문장 토큰화 (개행문자, 마침표로 문장 분리)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "text_sample = 'Matrix is everywhere its all around us, here even in this room. \\n You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes'\n",
    "\n",
    "#문장분리\n",
    "sentences = sent_tokenize(text=text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Matrix is everywhere its all around us, here even in this room.',\n",
       " 'You can see it out your window or on your television.',\n",
       " 'You feel it when you go to work, or go to church or pay your taxes']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마침표를 기준으로 3개의 문장으로 분리되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences), len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 분리\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Matrix',\n",
       " 'is',\n",
       " 'everywhere',\n",
       " 'its',\n",
       " 'all',\n",
       " 'around',\n",
       " 'us',\n",
       " ',',\n",
       " 'here',\n",
       " 'even',\n",
       " 'in',\n",
       " 'this',\n",
       " 'room',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence ='Matrix is everywhere its all around us, here even in this room.'\n",
    "word = word_tokenize(sentence)\n",
    "word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본적으로 쉼표, 마침표 , 개행문자 등으로 단어를 분리한다 -> 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장과 단어를 한번에 분리하는 함수 만들기\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "# parameter: text (문서)\n",
    "def tokenize_text(text):\n",
    "    # 문장 분리\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # 단어 분리\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]  #2차원 구조의 리스트로 저장됨\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample = 'Matrix is everywhere its all around us, here even in this room. \\n You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = tokenize_text(text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes']]\n"
     ]
    }
   ],
   "source": [
    "# 2차원 구조의 리스트로 토큰화됨\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스톱워드 제거(불용어 처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')  # 불용어 목록 다운받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영어의 불용어 개수 확인 (한국어는 지원안함)\n",
    "len(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거하기\n",
    "\n",
    "all_tokens = []\n",
    "# word_tokesn: 2차원 배열(단어들이 토큰화된 상태)\n",
    "\n",
    "for sentence in word_tokens:\n",
    "    filtered_words = []  # 불용어 걸러내서 저장할 공간\n",
    "    for word in sentence:\n",
    "        word = word.lower() # stop word 는 전부 소문자로 구성되어 있음\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    all_tokens.append(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어 제거된 토큰\n",
    "all_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Matrix',\n",
       " 'is',\n",
       " 'everywhere',\n",
       " 'its',\n",
       " 'all',\n",
       " 'around',\n",
       " 'us',\n",
       " ',',\n",
       " 'here',\n",
       " 'even',\n",
       " 'in',\n",
       " 'this',\n",
       " 'room',\n",
       " '.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#불용어 제거되기 전 토큰\n",
    "word_tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming 과 Lemmatization \n",
    "- 어간 추출(Stemming) and 표제어 추출(Lemmatization)\n",
    "- Lemmatization 이 더 정교함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('work', 'work', 'work')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('working'), stemmer.stem('works'), stemmer.stem('worked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('happy', 'happiest')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('happier'), stemmer.stem('happiest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- work는 제대로 인식, 비교급이나최상급은 제대로 인식 못함\n",
    "- Stemmer 보다 정교한 Lemmatizer 를 사용해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\TJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordnet 다운로드해주기\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('amuse', 'amuse', 'amuse')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('amusing','v'), lemma.lemmatize('amuses','v'), lemma.lemmatize('amused','v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy happy\n",
      "good good best\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('happier','a'), lemma.lemmatize('happiest','a'))\n",
    "print(lemma.lemmatize('good','a'), lemma.lemmatize('better','a'), lemma.lemmatize('best','a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lemmatization(WordNetLemmatizer) 를 이용하면 제대로 된다(대신에 형용사 동사 등의 품사 입력을 해주어야 한다.\n",
    "- Stemmer 보다 정확하게 원형단어를 추출해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Bac of Words - BOW\n",
    "- 단어를 숫자로 변환(Vectorizer): 개수로 변환\n",
    "- CountVectorizer 클래스 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 1\n",
    "text_sample_01 = 'Matrix is everywhere its all around us, here even in this room. \\n You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes'\n",
    "\n",
    "# 문서 2\n",
    "text_sample_02 = 'You take the blue pill and the story ends. You wake in your bed and you believe whatever you want to believe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ = []\n",
    "text_.append(text_sample_01)\n",
    "text_.append(text_sample_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Matrix is everywhere its all around us, here even in this room. \\n You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes',\n",
       " 'You take the blue pill and the story ends. You wake in your bed and you believe whatever you want to believe']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x42 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 46 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(text_)\n",
    "ftr_vect = cnt_vect.transform(text_)\n",
    "ftr_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sparse matrix : 2X42 희소행렬 생성됨, CSR(Compressed Sparese Row)되어서 빈 공간이 없게끔 압축된 상태의 numpy 객체 반환\n",
    "- 2 : 도큐먼트의 수\n",
    "- 42 : 단어의 수 \n",
    "- M X N (2 X 42) 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 벡터화 후 데이터 유형 및 여러 속성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<1x42 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 30 stored elements in Compressed Sparse Row format>,\n",
       " <1x42 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 16 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ftr_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (2, 42))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ftr_vect), ftr_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t2\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t2\n",
      "  (0, 17)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 20)\t3\n",
      "  (0, 21)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 32)\t2\n",
      "  (0, 33)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 40)\t3\n",
      "  (0, 41)\t3\n"
     ]
    }
   ],
   "source": [
    "# 문서 1의 vectorizing 확인 : text_sample_01\n",
    "print(ftr_vect[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t2\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t2\n",
      "  (0, 5)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 30)\t2\n",
      "  (0, 32)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 40)\t4\n",
      "  (0, 41)\t1\n"
     ]
    }
   ],
   "source": [
    "# 문서 2의 vectorizing 확인 : text_sample_02\n",
    "print(ftr_vect[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 42개가 아니라 뺄건 뺀상태로 압축된 애들만 담겨져 있다.(CSR) - 메모리 절약을 위한 작업\n",
    "- 즉 count 가 0인 애들은 빼버리고 개수를 가지고 있는 애들만 가져오는 방식\n",
    "\n",
    "####  나중에 학습시키기 위해서는 원본행렬로 원복해야한다(행렬이 차원이 맞아야 하므로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matrix': 18, 'is': 15, 'everywhere': 10, 'its': 17, 'all': 0, 'around': 2, 'us': 33, 'here': 13, 'even': 9, 'in': 14, 'this': 31, 'room': 24, 'you': 40, 'can': 6, 'see': 25, 'it': 16, 'out': 21, 'your': 41, 'window': 38, 'or': 20, 'on': 19, 'television': 29, 'feel': 11, 'when': 37, 'go': 12, 'to': 32, 'work': 39, 'church': 7, 'pay': 22, 'taxes': 28, 'take': 27, 'the': 30, 'blue': 5, 'pill': 23, 'and': 1, 'story': 26, 'ends': 8, 'wake': 34, 'bed': 3, 'believe': 4, 'whatever': 36, 'want': 35}\n"
     ]
    }
   ],
   "source": [
    "# csr_matrix 객체 안의 단어 추출하기\n",
    "print(cnt_vect.vocabulary_)\n",
    "# vocabulary_ 속성이 단어와 인덱스 정보를 딕셔너리 구조로 가지고 있다.(count 는 포함되지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopword 파라미터 추가하여 객체 생성후 확인\n",
    "cnt_vect = CountVectorizer(max_features=5, stop_words='english')\n",
    "cnt_vect.fit(text_)\n",
    "ftr_vect = cnt_vect.transform(text_)\n",
    "ftr_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'television': 2, 'wake': 3, 'bed': 0, 'believe': 1, 'want': 4}\n"
     ]
    }
   ],
   "source": [
    "# csr_matrix 객체 안의 단어 추출하기\n",
    "print(cnt_vect.vocabulary_)\n",
    "# stopword 제외된 애들의 핵심단어 확인가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram_range확인\n",
    " - 문맥의순서 정보를 유지하기 위한 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vect = CountVectorizer(ngram_range=(1,2)) # 1개짜리, 2개짜리 묶어서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x100 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 104 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vect.fit(text_)\n",
    "ftr_vect = cnt_vect.transform(text_)\n",
    "ftr_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matrix': 39, 'is': 32, 'everywhere': 21, 'its': 37, 'all': 0, 'around': 5, 'us': 73, 'here': 27, 'even': 19, 'in': 29, 'this': 67, 'room': 53, 'you': 87, 'can': 13, 'see': 55, 'it': 34, 'out': 47, 'your': 95, 'window': 83, 'or': 43, 'on': 41, 'television': 62, 'feel': 23, 'when': 81, 'go': 25, 'to': 69, 'work': 85, 'church': 15, 'pay': 49, 'taxes': 61, 'matrix is': 40, 'is everywhere': 33, 'everywhere its': 22, 'its all': 38, 'all around': 1, 'around us': 6, 'us here': 74, 'here even': 28, 'even in': 20, 'in this': 30, 'this room': 68, 'room you': 54, 'you can': 89, 'can see': 14, 'see it': 56, 'it out': 35, 'out your': 48, 'your window': 99, 'window or': 84, 'or on': 45, 'on your': 42, 'your television': 98, 'television you': 63, 'you feel': 90, 'feel it': 24, 'it when': 36, 'when you': 82, 'you go': 91, 'go to': 26, 'to work': 72, 'work or': 86, 'or go': 44, 'to church': 71, 'church or': 16, 'or pay': 46, 'pay your': 50, 'your taxes': 97, 'take': 59, 'the': 64, 'blue': 11, 'pill': 51, 'and': 2, 'story': 57, 'ends': 17, 'wake': 75, 'bed': 7, 'believe': 9, 'whatever': 79, 'want': 77, 'you take': 92, 'take the': 60, 'the blue': 65, 'blue pill': 12, 'pill and': 52, 'and the': 3, 'the story': 66, 'story ends': 58, 'ends you': 18, 'you wake': 93, 'wake in': 76, 'in your': 31, 'your bed': 96, 'bed and': 8, 'and you': 4, 'you believe': 88, 'believe whatever': 10, 'whatever you': 80, 'you want': 94, 'want to': 78, 'to believe': 70}\n"
     ]
    }
   ],
   "source": [
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matrix': 61, 'is': 50, 'everywhere': 32, 'its': 58, 'all': 0, 'around': 8, 'us': 113, 'here': 42, 'even': 29, 'in': 45, 'this': 104, 'room': 83, 'you': 134, 'can': 20, 'see': 86, 'it': 53, 'out': 74, 'your': 149, 'window': 128, 'or': 67, 'on': 64, 'television': 96, 'feel': 35, 'when': 125, 'go': 38, 'to': 107, 'work': 131, 'church': 23, 'pay': 77, 'taxes': 95, 'matrix is': 62, 'is everywhere': 51, 'everywhere its': 33, 'its all': 59, 'all around': 1, 'around us': 9, 'us here': 114, 'here even': 43, 'even in': 30, 'in this': 46, 'this room': 105, 'room you': 84, 'you can': 137, 'can see': 21, 'see it': 87, 'it out': 54, 'out your': 75, 'your window': 155, 'window or': 129, 'or on': 70, 'on your': 65, 'your television': 153, 'television you': 97, 'you feel': 139, 'feel it': 36, 'it when': 56, 'when you': 126, 'you go': 141, 'go to': 39, 'to work': 111, 'work or': 132, 'or go': 68, 'to church': 109, 'church or': 24, 'or pay': 72, 'pay your': 78, 'your taxes': 152, 'matrix is everywhere': 63, 'is everywhere its': 52, 'everywhere its all': 34, 'its all around': 60, 'all around us': 2, 'around us here': 10, 'us here even': 115, 'here even in': 44, 'even in this': 31, 'in this room': 47, 'this room you': 106, 'room you can': 85, 'you can see': 138, 'can see it': 22, 'see it out': 88, 'it out your': 55, 'out your window': 76, 'your window or': 156, 'window or on': 130, 'or on your': 71, 'on your television': 66, 'your television you': 154, 'television you feel': 98, 'you feel it': 140, 'feel it when': 37, 'it when you': 57, 'when you go': 127, 'you go to': 142, 'go to work': 41, 'to work or': 112, 'work or go': 133, 'or go to': 69, 'go to church': 40, 'to church or': 110, 'church or pay': 25, 'or pay your': 73, 'pay your taxes': 79, 'take': 92, 'the': 99, 'blue': 17, 'pill': 80, 'and': 3, 'story': 89, 'ends': 26, 'wake': 116, 'bed': 11, 'believe': 14, 'whatever': 122, 'want': 119, 'you take': 143, 'take the': 93, 'the blue': 100, 'blue pill': 18, 'pill and': 81, 'and the': 4, 'the story': 102, 'story ends': 90, 'ends you': 27, 'you wake': 145, 'wake in': 117, 'in your': 48, 'your bed': 150, 'bed and': 12, 'and you': 6, 'you believe': 135, 'believe whatever': 15, 'whatever you': 123, 'you want': 147, 'want to': 120, 'to believe': 108, 'you take the': 144, 'take the blue': 94, 'the blue pill': 101, 'blue pill and': 19, 'pill and the': 82, 'and the story': 5, 'the story ends': 103, 'story ends you': 91, 'ends you wake': 28, 'you wake in': 146, 'wake in your': 118, 'in your bed': 49, 'your bed and': 151, 'bed and you': 13, 'and you believe': 7, 'you believe whatever': 136, 'believe whatever you': 16, 'whatever you want': 124, 'you want to': 148, 'want to believe': 121}\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer(ngram_range=(1,3)) # (범위 최소값, 범위 최대값)즉 1단어, 2단어, 3단어를 다 출력\n",
    "cnt_vect.fit(text_)\n",
    "ftr_vect = cnt_vect.transform(text_)\n",
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matrix is': 43, 'is everywhere': 35, 'everywhere its': 22, 'its all': 41, 'all around': 0, 'around us': 6, 'us here': 80, 'here even': 29, 'even in': 20, 'in this': 31, 'this room': 73, 'room you': 59, 'you can': 96, 'can see': 14, 'see it': 61, 'it out': 37, 'out your': 53, 'your window': 113, 'window or': 90, 'or on': 49, 'on your': 45, 'your television': 111, 'television you': 67, 'you feel': 98, 'feel it': 24, 'it when': 39, 'when you': 88, 'you go': 100, 'go to': 26, 'to work': 78, 'work or': 92, 'or go': 47, 'to church': 76, 'church or': 16, 'or pay': 51, 'pay your': 55, 'your taxes': 110, 'matrix is everywhere': 44, 'is everywhere its': 36, 'everywhere its all': 23, 'its all around': 42, 'all around us': 1, 'around us here': 7, 'us here even': 81, 'here even in': 30, 'even in this': 21, 'in this room': 32, 'this room you': 74, 'room you can': 60, 'you can see': 97, 'can see it': 15, 'see it out': 62, 'it out your': 38, 'out your window': 54, 'your window or': 114, 'window or on': 91, 'or on your': 50, 'on your television': 46, 'your television you': 112, 'television you feel': 68, 'you feel it': 99, 'feel it when': 25, 'it when you': 40, 'when you go': 89, 'you go to': 101, 'go to work': 28, 'to work or': 79, 'work or go': 93, 'or go to': 48, 'go to church': 27, 'to church or': 77, 'church or pay': 17, 'or pay your': 52, 'pay your taxes': 56, 'you take': 102, 'take the': 65, 'the blue': 69, 'blue pill': 12, 'pill and': 57, 'and the': 2, 'the story': 71, 'story ends': 63, 'ends you': 18, 'you wake': 104, 'wake in': 82, 'in your': 33, 'your bed': 108, 'bed and': 8, 'and you': 4, 'you believe': 94, 'believe whatever': 10, 'whatever you': 86, 'you want': 106, 'want to': 84, 'to believe': 75, 'you take the': 103, 'take the blue': 66, 'the blue pill': 70, 'blue pill and': 13, 'pill and the': 58, 'and the story': 3, 'the story ends': 72, 'story ends you': 64, 'ends you wake': 19, 'you wake in': 105, 'wake in your': 83, 'in your bed': 34, 'your bed and': 109, 'bed and you': 9, 'and you believe': 5, 'you believe whatever': 95, 'believe whatever you': 11, 'whatever you want': 87, 'you want to': 107, 'want to believe': 85}\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer(ngram_range=(2,3)) # (범위 최소값, 범위 최대값)\n",
    "cnt_vect.fit(text_)\n",
    "ftr_vect = cnt_vect.transform(text_)\n",
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matrix is': 21, 'is everywhere': 17, 'everywhere its': 11, 'its all': 20, 'all around': 0, 'around us': 3, 'us here': 40, 'here even': 14, 'even in': 10, 'in this': 15, 'this room': 36, 'room you': 29, 'you can': 48, 'can see': 7, 'see it': 30, 'it out': 18, 'out your': 26, 'your window': 57, 'window or': 45, 'or on': 24, 'on your': 22, 'your television': 56, 'television you': 33, 'you feel': 49, 'feel it': 12, 'it when': 19, 'when you': 44, 'you go': 50, 'go to': 13, 'to work': 39, 'work or': 46, 'or go': 23, 'to church': 38, 'church or': 8, 'or pay': 25, 'pay your': 27, 'your taxes': 55, 'you take': 51, 'take the': 32, 'the blue': 34, 'blue pill': 6, 'pill and': 28, 'and the': 1, 'the story': 35, 'story ends': 31, 'ends you': 9, 'you wake': 52, 'wake in': 41, 'in your': 16, 'your bed': 54, 'bed and': 4, 'and you': 2, 'you believe': 47, 'believe whatever': 5, 'whatever you': 43, 'you want': 53, 'want to': 42, 'to believe': 37}\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer(ngram_range=(2,2)) # 2개 단어 묶은 거만 모음\n",
    "cnt_vect.fit(text_)\n",
    "ftr_vect = cnt_vect.transform(text_)\n",
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 희소행렬 - COO 형식\n",
    "- COO : (Cordinate: 좌표) 형식 : 0 이 아닌 데이터만 별도의 데이터 배열에 저장하고, 그 데이터가 가리키는 행과 열의 위치를 별도로 저장\n",
    "- scipy 모듈의 sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dense = np.array([[3,0,1],[0,2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 이 아닌 데이터추출\n",
    "data = np.array([3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_pos = np.array([0,0,1])\n",
    "col_pos = np.array([0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_coo = sparse.coo_matrix((data, (row_pos, col_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t3\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t2\n"
     ]
    }
   ],
   "source": [
    "print(sparse_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 1]\n",
      " [0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "# 희소 행렬을 원래 데이터 복원(학습을 하려면 원본데이터로 복원해서 행렬차원을 맞춰줘야한다.)\n",
    "# toarray() function 사용하기!\n",
    "dense01 = sparse_coo.toarray()\n",
    "print(dense01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 희소행렬 - CSR 형식\n",
    "- CSR(Compressed Sparse Row) : COO형식이 행열 위치를 나타내기 위해 반복적인 위치데이터 사용해야 하는 문제점 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.485~ 참고해서 코딩하기\n",
    "# COO 형식으로 변환\n",
    "dense02 = \n",
    "\n",
    "# 행위치 배열의 고유한 값들의 시작위치 인덱스를 배열로 생성\n",
    "\n",
    "# CSR 형식으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- toarray() 기능으로 원래의 행열로 복원시키는 것이 중요 : 그래야 모델생성을 할수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml01-02",
   "language": "python",
   "name": "ml01-02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
