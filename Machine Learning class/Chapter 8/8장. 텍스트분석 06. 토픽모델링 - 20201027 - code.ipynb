{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "- 비지도학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 의학, 우주 주제를 추출. \n",
    "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
    "\n",
    "# 위에서 cats 변수로 기재된 category만 추출. featch_20newsgroups( )의 categories에 cats 입력\n",
    "news_df= fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'), \n",
    "                            categories=cats, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shape: (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "# 벡터화\n",
    "# LDA 는 Count기반의 Vectorizer만 적용합니다.  \n",
    "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1,2))\n",
    "feat_vect = count_vect.fit_transform(news_df.data)\n",
    "print('CountVectorizer Shape:', feat_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=8, random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8개로 분리(하이퍼 파라미터 지정)\n",
    "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 각 토픽 모델링 주제별 단어들의 연관도 확인\n",
    "- LDA 객체의 components_ 속성은 주제별로 개별 단어들의 연관도 정규화 숫자가 들어있음\n",
    "- shape는 주제 개수 X 피처 단어 개수\n",
    "- components_에 들어 있는 숫자값은 각 주제별로 단어가 나타난 횟수를 정규화 하여 나타냄\n",
    "- 숫자가 클 수록 토픽에서 단어가 차지하는 비중이 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36.09920176, 135.62679793,  21.57518668,  16.67973737,\n",
       "        27.91164531,  51.08874696,  27.15781184, 563.62985361,\n",
       "       151.25501234, 250.00265828])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어별 토픽 분류 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topic_words(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print('Topic #',topic_index)\n",
    "        \n",
    "        # components_ array에서 가장 값이 큰순으로 정렬했을때, 그 값의 array index를 반환\n",
    "        topic_word_indexes = topic.argsort()[::-1]\n",
    "        top_indexes = topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        # top_indexes 대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
    "        feature_concat = ' + '.join(str(feature_names[i]) + ' * ' + str(round(topic[i],1)) for i in top_indexes)\n",
    "        print(feature_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어들을 sort해서 보여줌\n",
    "len(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic # 0\n",
      "year * 703.2 + 10 * 563.6 + game * 476.3 + medical * 413.2 + health * 377.4 + team * 346.8 + 12 * 343.9 + 20 * 340.9 + disease * 332.1 + cancer * 319.9 + 1993 * 318.3 + games * 317.0 + years * 306.5 + patients * 299.8 + good * 286.3\n",
      "Topic # 1\n",
      "don * 1454.3 + just * 1392.8 + like * 1190.8 + know * 1178.1 + people * 836.9 + said * 802.5 + think * 799.7 + time * 754.2 + ve * 676.3 + didn * 675.9 + right * 636.3 + going * 625.4 + say * 620.7 + ll * 583.9 + way * 570.3\n",
      "Topic # 2\n",
      "image * 1047.7 + file * 999.1 + jpeg * 799.1 + program * 495.6 + gif * 466.0 + images * 443.7 + output * 442.3 + format * 442.3 + files * 438.5 + color * 406.3 + entry * 387.6 + 00 * 334.8 + use * 308.5 + bit * 308.4 + 03 * 258.7\n",
      "Topic # 3\n",
      "like * 620.7 + know * 591.7 + don * 543.7 + think * 528.4 + use * 514.3 + does * 510.2 + just * 509.1 + good * 425.8 + time * 417.4 + book * 410.7 + read * 402.9 + information * 395.2 + people * 393.5 + used * 388.2 + post * 368.4\n",
      "Topic # 4\n",
      "armenian * 960.6 + israel * 815.9 + armenians * 699.7 + jews * 690.9 + turkish * 686.1 + people * 653.0 + israeli * 476.1 + jewish * 467.0 + government * 464.4 + war * 417.8 + dos dos * 401.1 + turkey * 393.5 + arab * 386.1 + armenia * 346.3 + 000 * 345.2\n",
      "Topic # 5\n",
      "edu * 1613.5 + com * 841.4 + available * 761.5 + graphics * 708.0 + ftp * 668.1 + data * 517.9 + pub * 508.2 + motif * 460.4 + mail * 453.3 + widget * 447.4 + software * 427.6 + mit * 421.5 + information * 417.3 + version * 413.7 + sun * 402.4\n",
      "Topic # 6\n",
      "god * 2013.0 + people * 721.0 + jesus * 688.7 + church * 663.0 + believe * 563.0 + christ * 553.1 + does * 500.1 + christian * 474.8 + say * 468.6 + think * 446.0 + christians * 443.5 + bible * 422.9 + faith * 420.1 + sin * 396.5 + life * 371.2\n",
      "Topic # 7\n",
      "use * 685.8 + dos * 635.0 + thanks * 596.0 + windows * 548.7 + using * 486.5 + window * 483.1 + does * 456.2 + display * 389.1 + help * 385.2 + like * 382.8 + problem * 375.7 + server * 370.2 + need * 366.3 + know * 355.5 + run * 315.3\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer객체내의 전체 word들의 명칭을 get_features_name를 초해 추출\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "# Topic별 가장 연관도가 높은 word를 15개만 추출\n",
    "display_topic_words(lda, feature_names, 15)\n",
    "\n",
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 의학, 우주 주제를 추출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별 문서별 토픽 분포 확인\n",
    "lda 객체의 transform()을 수행하면 개별 문서별 토픽 분포를 반환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7862, 8)\n",
      "[[0.01389701 0.01394362 0.01389104 0.48221844 0.01397882 0.01389205\n",
      "  0.01393501 0.43424401]\n",
      " [0.27750436 0.18151826 0.0021208  0.53037189 0.00212129 0.00212102\n",
      "  0.00212113 0.00212125]\n",
      " [0.00544459 0.22166575 0.00544539 0.00544528 0.00544039 0.00544168\n",
      "  0.00544182 0.74567512]]\n"
     ]
    }
   ],
   "source": [
    "doc_topics = lda.transform(feat_vect)\n",
    "print(doc_topics.shape)\n",
    "print(doc_topics[:3])\n",
    "\n",
    "# 7862 : document count , 8 : topic term(단어) count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별 문서별 토픽 분포도를 출력\n",
    "- 20newsgroup으로 만들어진 문서명을 출력\n",
    "- fetch_20newsgroup()으로 만들어진 데이터의 filename속성은 모든 문서의 문서명을 가지고 있음\n",
    "- filename 속성은 절대 디렉토리를 가지는 문서명을 가지고 있으므로 '\\'로 분할하여 맨 마지작 두번째 부터 파일명을 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_list(newsdata):\n",
    "    filename_list = []\n",
    "    \n",
    "    for file in newsdata.filenames:\n",
    "#         print(file)\n",
    "        filename_temp = file.split('\\\\')[-2:]\n",
    "        filename = '.'.join(filename_temp)\n",
    "        filename_list.append(filename)\n",
    "    return filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename 개수 :  7862  filename list 10개만 :  ['soc.religion.christian.20630', 'sci.med.59422', 'comp.graphics.38765', 'comp.graphics.38810', 'sci.med.59449', 'comp.graphics.38461', 'comp.windows.x.66959', 'rec.motorcycles.104487', 'sci.electronics.53875', 'sci.electronics.53617']\n"
     ]
    }
   ],
   "source": [
    "filename_list = get_filename_list(news_df)\n",
    "\n",
    "print('filename 개수 : ', len(filename_list), ' filename list 10개만 : ', filename_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic #0</th>\n",
       "      <th>Topic #1</th>\n",
       "      <th>Topic #2</th>\n",
       "      <th>Topic #3</th>\n",
       "      <th>Topic #4</th>\n",
       "      <th>Topic #5</th>\n",
       "      <th>Topic #6</th>\n",
       "      <th>Topic #7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian.20630</th>\n",
       "      <td>0.013897</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>0.482218</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.013892</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.434244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med.59422</th>\n",
       "      <td>0.277504</td>\n",
       "      <td>0.181518</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.530372</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.002121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics.38765</th>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.221666</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.745675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics.38810</th>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.578959</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.388387</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med.59449</th>\n",
       "      <td>0.006584</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.408485</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.006585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Topic #0  Topic #1  Topic #2  Topic #3  \\\n",
       "soc.religion.christian.20630  0.013897  0.013944  0.013891  0.482218   \n",
       "sci.med.59422                 0.277504  0.181518  0.002121  0.530372   \n",
       "comp.graphics.38765           0.005445  0.221666  0.005445  0.005445   \n",
       "comp.graphics.38810           0.005439  0.005441  0.005449  0.578959   \n",
       "sci.med.59449                 0.006584  0.552000  0.006587  0.408485   \n",
       "\n",
       "                              Topic #4  Topic #5  Topic #6  Topic #7  \n",
       "soc.religion.christian.20630  0.013979  0.013892  0.013935  0.434244  \n",
       "sci.med.59422                 0.002121  0.002121  0.002121  0.002121  \n",
       "comp.graphics.38765           0.005440  0.005442  0.005442  0.745675  \n",
       "comp.graphics.38810           0.005440  0.388387  0.005442  0.005442  \n",
       "sci.med.59449                 0.006585  0.006585  0.006588  0.006585  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topic_names = ['Topic #' + str(i) for i in range(0,8)]\n",
    "\n",
    "doc_topic_df = pd.DataFrame(\n",
    "    data=doc_topics   # transform 한 애\n",
    "    , columns=topic_names\n",
    "    , index=filename_list\n",
    ")\n",
    "\n",
    "doc_topic_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml01-02",
   "language": "python",
   "name": "ml01-02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
